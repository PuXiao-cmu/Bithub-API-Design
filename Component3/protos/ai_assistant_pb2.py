# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: ai_assistant.proto
# Protobuf Python Version: 5.28.1
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC,
    5,
    28,
    1,
    '',
    'ai_assistant.proto'
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x12\x61i_assistant.proto\x12\x0c\x61i_assistant\"6\n\x19WritePRDescriptionRequest\x12\x19\n\x11\x63ommitted_changes\x18\x01 \x01(\t\"4\n\x1aWritePRDescriptionResponse\x12\x16\n\x0epr_description\x18\x01 \x01(\t\"l\n\x07\x43ontext\x12\x14\n\x0crepo_content\x18\x01 \x01(\t\x12\x19\n\x11\x63ommitted_changes\x18\x02 \x01(\t\x12\x1b\n\x13uncommitted_changes\x18\x03 \x01(\t\x12\x13\n\x0b\x63urr_branch\x18\x04 \x01(\t\"`\n\x18SmartAutoCompleteRequest\x12.\n\x0f\x63urrent_context\x18\x01 \x01(\x0b\x32\x15.ai_assistant.Context\x12\x14\n\x0crecent_edits\x18\x02 \x01(\t\"4\n\x19SmartAutoCompleteResponse\x12\x17\n\x0f\x63ode_completion\x18\x01 \x01(\t\"c\n\x15\x43hatGPTForCodeRequest\x12\x18\n\x10task_description\x18\x01 \x01(\t\x12\x16\n\x0e\x63ommitted_code\x18\x02 \x01(\t\x12\x18\n\x10uncommitted_code\x18\x03 \x01(\t\"V\n\x16\x43hatGPTForCodeResponse\x12\x1f\n\x15\x63larification_request\x18\x01 \x01(\tH\x00\x12\x0f\n\x05\x64\x65lta\x18\x02 \x01(\tH\x00\x42\n\n\x08response\"V\n\x13\x43onversationContext\x12\x15\n\rexisting_code\x18\x01 \x01(\t\x12\x13\n\x0bstack_trace\x18\x02 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x03 \x01(\t\"Y\n\x13\x43onversationRequest\x12\x32\n\x07\x63ontext\x18\x01 \x01(\x0b\x32!.ai_assistant.ConversationContext\x12\x0e\n\x06is_end\x18\x02 \x01(\x08\"C\n\x14\x43onversationResponse\x12\x16\n\x0eproposed_delta\x18\x01 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x02 \x01(\t2\xa4\x03\n\x0b\x41IAssistant\x12i\n\x12WritePRDescription\x12\'.ai_assistant.WritePRDescriptionRequest\x1a(.ai_assistant.WritePRDescriptionResponse\"\x00\x12\x66\n\x11SmartAutoComplete\x12&.ai_assistant.SmartAutoCompleteRequest\x1a\'.ai_assistant.SmartAutoCompleteResponse\"\x00\x12]\n\x0e\x43hatGPTForCode\x12#.ai_assistant.ChatGPTForCodeRequest\x1a$.ai_assistant.ChatGPTForCodeResponse\"\x00\x12\x63\n\x14VirtualPairAssistant\x12!.ai_assistant.ConversationRequest\x1a\".ai_assistant.ConversationResponse\"\x00(\x01\x30\x01\x62\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'ai_assistant_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  DESCRIPTOR._loaded_options = None
  _globals['_WRITEPRDESCRIPTIONREQUEST']._serialized_start=36
  _globals['_WRITEPRDESCRIPTIONREQUEST']._serialized_end=90
  _globals['_WRITEPRDESCRIPTIONRESPONSE']._serialized_start=92
  _globals['_WRITEPRDESCRIPTIONRESPONSE']._serialized_end=144
  _globals['_CONTEXT']._serialized_start=146
  _globals['_CONTEXT']._serialized_end=254
  _globals['_SMARTAUTOCOMPLETEREQUEST']._serialized_start=256
  _globals['_SMARTAUTOCOMPLETEREQUEST']._serialized_end=352
  _globals['_SMARTAUTOCOMPLETERESPONSE']._serialized_start=354
  _globals['_SMARTAUTOCOMPLETERESPONSE']._serialized_end=406
  _globals['_CHATGPTFORCODEREQUEST']._serialized_start=408
  _globals['_CHATGPTFORCODEREQUEST']._serialized_end=507
  _globals['_CHATGPTFORCODERESPONSE']._serialized_start=509
  _globals['_CHATGPTFORCODERESPONSE']._serialized_end=595
  _globals['_CONVERSATIONCONTEXT']._serialized_start=597
  _globals['_CONVERSATIONCONTEXT']._serialized_end=683
  _globals['_CONVERSATIONREQUEST']._serialized_start=685
  _globals['_CONVERSATIONREQUEST']._serialized_end=774
  _globals['_CONVERSATIONRESPONSE']._serialized_start=776
  _globals['_CONVERSATIONRESPONSE']._serialized_end=843
  _globals['_AIASSISTANT']._serialized_start=846
  _globals['_AIASSISTANT']._serialized_end=1266
# @@protoc_insertion_point(module_scope)
